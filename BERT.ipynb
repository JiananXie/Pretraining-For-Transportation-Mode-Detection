{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "# path = 'D:/SHL_dataset' #解压文件的文件夹目录\n",
    "# target_folder = 'D:/SHL_dataset'#要提取到的文件夹目录\n",
    "# folder_list = os.listdir(path=path + '/SHLDataset_User1Hips_v2/release/User1')\n",
    "# for folder in folder_list:\n",
    "#     file_name_motion = 'Hips_Motion.txt'\n",
    "#     file_name_label = 'Label.txt'\n",
    "#     source_path_motion = os.path.join(path + '/SHLDataset_User1Hips_v2/release/User1/'+folder, file_name_motion)\n",
    "#     source_path_label = os.path.join(path + '/SHLDataset_User1Hips_v2/release/User1/'+folder, file_name_label)\n",
    "#     target_path_motion = os.path.join(target_folder , folder)\n",
    "#     target_path_label = os.path.join(target_folder, folder)\n",
    "    \n",
    "#     if os.path.isfile(source_path_motion) and os.path.isfile(source_path_label):\n",
    "#         os.makedirs(os.path.join(target_folder, folder))\n",
    "#         shutil.move(source_path_motion, target_path_motion)\n",
    "#         shutil.move(source_path_label, target_path_label)\n",
    "#         print(f\"Moved file {source_path_motion} and {source_path_label} to {target_path_motion},{target_path_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['170301',\n",
       "  '170302',\n",
       "  '170303',\n",
       "  '170306',\n",
       "  '170307',\n",
       "  '170308',\n",
       "  '170309',\n",
       "  '170310',\n",
       "  '170313',\n",
       "  '170314',\n",
       "  '170315',\n",
       "  '170316',\n",
       "  '170317',\n",
       "  '170320',\n",
       "  '170321',\n",
       "  '170322',\n",
       "  '170323',\n",
       "  '170324',\n",
       "  '170325',\n",
       "  '170327',\n",
       "  '170328',\n",
       "  '170329',\n",
       "  '170330',\n",
       "  '170418',\n",
       "  '170419',\n",
       "  '170420',\n",
       "  '170424',\n",
       "  '170425',\n",
       "  '170426',\n",
       "  '170427',\n",
       "  '170428',\n",
       "  '170502',\n",
       "  '170503',\n",
       "  '170504',\n",
       "  '170505',\n",
       "  '170508',\n",
       "  '170509',\n",
       "  '170510',\n",
       "  '170511',\n",
       "  '170512',\n",
       "  '170515',\n",
       "  '170517',\n",
       "  '170519',\n",
       "  '170520',\n",
       "  '170522',\n",
       "  '170523',\n",
       "  '170524',\n",
       "  '170525',\n",
       "  '170526',\n",
       "  '170529',\n",
       "  '170530',\n",
       "  '170531',\n",
       "  '170601',\n",
       "  '170602',\n",
       "  '170603',\n",
       "  '170605',\n",
       "  '170606',\n",
       "  '170607',\n",
       "  '170608',\n",
       "  '170609',\n",
       "  '170612',\n",
       "  '170613',\n",
       "  '170614',\n",
       "  '170615',\n",
       "  '170620',\n",
       "  '170622',\n",
       "  '170623',\n",
       "  '170626',\n",
       "  '170627',\n",
       "  '170628',\n",
       "  '170629',\n",
       "  '170630',\n",
       "  '170703',\n",
       "  '170704',\n",
       "  '170705'],\n",
       " 75,\n",
       " ['m170301',\n",
       "  'm170303',\n",
       "  'm170317',\n",
       "  'm170324',\n",
       "  'm170329',\n",
       "  'm170424',\n",
       "  'm170428',\n",
       "  'm170508',\n",
       "  'm170515',\n",
       "  'm170522',\n",
       "  'm170530',\n",
       "  'm170605',\n",
       "  'm170609',\n",
       "  'm170629',\n",
       "  'm170706'],\n",
       " 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "folder_list = os.listdir('D:/SHL/SHL_dataset')\n",
    "day_list = []\n",
    "miday_list = []\n",
    "for l in folder_list:\n",
    "    if 'm' not in l:\n",
    "        day_list.append(l)\n",
    "    else:\n",
    "        miday_list.append(l)\n",
    "\n",
    "day_list = [ x[4:6] + x[2:4] + x[0:2] for x in day_list]\n",
    "day_list.sort()\n",
    "miday_list= [x[0] + x[5:7] + x[3:5] + x[1:3] for x in miday_list]\n",
    "miday_list.sort()\n",
    "day_list, len(day_list), miday_list, len(miday_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 010317...\n",
      "working on 010617...\n",
      "working on 020317...\n",
      "working on 020517...\n",
      "working on 020617...\n",
      "working on 030317...\n",
      "working on 030517...\n",
      "working on 030617...\n",
      "working on 030717...\n",
      "working on 040517...\n",
      "working on 040717...\n",
      "working on 050517...\n",
      "working on 050617...\n",
      "working on 050717...\n",
      "working on 060317...\n",
      "working on 060617...\n",
      "working on 070317...\n",
      "working on 070617...\n",
      "working on 080317...\n",
      "working on 080517...\n",
      "working on 080617...\n",
      "working on 090317...\n",
      "working on 090517...\n",
      "working on 090617...\n",
      "working on 100317...\n",
      "working on 100517...\n",
      "working on 110517...\n",
      "working on 120517...\n",
      "working on 120617...\n",
      "working on 130317...\n",
      "working on 130617...\n",
      "working on 140317...\n",
      "working on 140617...\n",
      "working on 150317...\n",
      "working on 150517...\n",
      "working on 150617...\n",
      "working on 160317...\n",
      "working on 170317...\n",
      "working on 170517...\n",
      "working on 180417...\n",
      "working on 190417...\n",
      "working on 190517...\n",
      "working on 200317...\n",
      "working on 200417...\n",
      "working on 200517...\n",
      "working on 200617...\n",
      "working on 210317...\n",
      "working on 220317...\n",
      "working on 220517...\n",
      "working on 220617...\n",
      "working on 230317...\n",
      "working on 230517...\n",
      "working on 230617...\n",
      "working on 240317...\n",
      "working on 240417...\n",
      "working on 240517...\n",
      "working on 250317...\n",
      "working on 250417...\n",
      "working on 250517...\n",
      "working on 260417...\n",
      "working on 260517...\n",
      "working on 260617...\n",
      "working on 270317...\n",
      "working on 270417...\n",
      "working on 270617...\n",
      "working on 280317...\n",
      "working on 280417...\n",
      "working on 280617...\n",
      "working on 290317...\n",
      "working on 290517...\n",
      "working on 290617...\n",
      "working on 300317...\n",
      "working on 300517...\n",
      "working on 300617...\n",
      "working on 310517...\n",
      "working on m010317...\n",
      "working on m030317...\n",
      "working on m050617...\n",
      "working on m060717...\n",
      "working on m080517...\n",
      "working on m090617...\n",
      "working on m150517...\n",
      "working on m170317...\n",
      "working on m220517...\n",
      "working on m240317...\n",
      "working on m240417...\n",
      "working on m280417...\n",
      "working on m290317...\n",
      "working on m290617...\n",
      "working on m300517...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "140729469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#统计data无nan值同时label非null的数据量\n",
    "path = 'D:/SHL/SHL_dataset/'\n",
    "data_file = '/Hips_Motion.txt'\n",
    "label_file = '/Label.txt'\n",
    "num = 0\n",
    "valid_timestamp = []\n",
    "for folder in folder_list:\n",
    "    print(f'working on {folder}...')\n",
    "    df = pd.read_csv(path + folder + data_file, header=None, delimiter=' ')\n",
    "    df_label = pd.read_csv(path + folder + label_file, header=None, delimiter=' ')\n",
    "    no_nan_df = df[df.notna().all(axis=1)]\n",
    "    no_null_df_label = df_label[df_label[1] != 0]\n",
    "    data_1 = set(no_nan_df[0].astype('int64'))\n",
    "    data_2 = set(no_null_df_label[0])\n",
    "    data_3 = data_1.intersection(data_2)\n",
    "    num += len(data_3)\n",
    "    valid_timestamp.append(list(data_3))\n",
    "num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #删除\n",
    "# for folder in folder_list:\n",
    "#     os.remove(path + folder + '/Hips_Motion.csv')\n",
    "#     os.remove(path + folder + '/Label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on 010317\n",
      "working on 010617\n",
      "working on 020317\n",
      "working on 020517\n",
      "working on 020617\n",
      "working on 030317\n",
      "working on 030517\n",
      "working on 030617\n",
      "working on 030717\n",
      "working on 040517\n",
      "working on 040717\n",
      "working on 050517\n",
      "working on 050617\n",
      "working on 050717\n",
      "working on 060317\n",
      "working on 060617\n",
      "working on 070317\n",
      "working on 070617\n",
      "working on 080317\n",
      "working on 080517\n",
      "working on 080617\n",
      "working on 090317\n",
      "working on 090517\n",
      "working on 090617\n",
      "working on 100317\n",
      "working on 100517\n",
      "working on 110517\n",
      "working on 120517\n",
      "working on 120617\n",
      "working on 130317\n",
      "working on 130617\n",
      "working on 140317\n",
      "working on 140617\n",
      "working on 150317\n",
      "working on 150517\n",
      "working on 150617\n",
      "working on 160317\n",
      "working on 170317\n",
      "working on 170517\n",
      "working on 180417\n",
      "working on 190417\n",
      "working on 190517\n",
      "working on 200317\n",
      "working on 200417\n",
      "working on 200517\n",
      "working on 200617\n",
      "working on 210317\n",
      "working on 220317\n",
      "working on 220517\n",
      "working on 220617\n",
      "working on 230317\n",
      "working on 230517\n",
      "working on 230617\n",
      "working on 240317\n",
      "working on 240417\n",
      "working on 240517\n",
      "working on 250317\n",
      "working on 250417\n",
      "working on 250517\n",
      "working on 260417\n",
      "working on 260517\n",
      "working on 260617\n",
      "working on 270317\n",
      "working on 270417\n",
      "working on 270617\n",
      "working on 280317\n",
      "working on 280417\n",
      "working on 280617\n",
      "working on 290317\n",
      "working on 290517\n",
      "working on 290617\n",
      "working on 300317\n",
      "working on 300517\n",
      "working on 300617\n",
      "working on 310517\n",
      "working on m010317\n",
      "working on m030317\n",
      "working on m050617\n",
      "working on m060717\n",
      "working on m080517\n",
      "working on m090617\n",
      "working on m150517\n",
      "working on m170317\n",
      "working on m220517\n",
      "working on m240317\n",
      "working on m240417\n",
      "working on m280417\n",
      "working on m290317\n",
      "working on m290617\n",
      "working on m300517\n"
     ]
    }
   ],
   "source": [
    "# #整理出新的数据集\n",
    "# for id, folder in enumerate(folder_list):\n",
    "#     print(f'working on {folder}')\n",
    "#     df = pd.read_csv(path + folder + data_file, header=None, delimiter=' ')\n",
    "#     df_label = pd.read_csv(path + folder + label_file, header=None, delimiter=' ')\n",
    "#     data = df[df[0].astype('int64').isin(valid_timestamp[id])]\n",
    "#     label = df_label[df_label[0].isin(valid_timestamp[id])]\n",
    "#     os.remove(path + folder + '/Hips_Motion.txt')\n",
    "#     os.remove(path + folder + '/Label.txt')\n",
    "#     data.to_csv(path + folder + '/Hips_Motion.csv', index=False)\n",
    "#     label.to_csv(path + folder + '/Label.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime(2017,3,1,13,57,2).timestamp()\n",
    "timestamp*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
